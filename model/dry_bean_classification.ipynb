{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fc967c0-fc44-4919-82e5-3eaa82213a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "from tabulate import tabulate\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import (accuracy_score, roc_auc_score, precision_score, recall_score, f1_score, matthews_corrcoef)\n",
    "\n",
    "# import models from sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cf0421a-ee12-461d-add2-4efdce2cd43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Name    :  Dry Bean\n",
      "Dataset Source  :  UCI\n",
      "No. of Samples  :  13611\n",
      "No. of Features :  17\n",
      "\n",
      "First 5 rows of the raw dataset:\n",
      "    Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRation  \\\n",
      "0  28395    610.291       208.178117       173.888747      1.197191   \n",
      "1  28734    638.018       200.524796       182.734419      1.097356   \n",
      "2  29380    624.110       212.826130       175.931143      1.209713   \n",
      "3  30008    645.884       210.557999       182.516516      1.153638   \n",
      "4  30140    620.134       201.847882       190.279279      1.060798   \n",
      "\n",
      "   Eccentricity  ConvexArea  EquivDiameter    Extent  Solidity  roundness  \\\n",
      "0      0.549812       28715     190.141097  0.763923  0.988856   0.958027   \n",
      "1      0.411785       29172     191.272750  0.783968  0.984986   0.887034   \n",
      "2      0.562727       29690     193.410904  0.778113  0.989559   0.947849   \n",
      "3      0.498616       30724     195.467062  0.782681  0.976696   0.903936   \n",
      "4      0.333680       30417     195.896503  0.773098  0.990893   0.984877   \n",
      "\n",
      "   Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  ShapeFactor4  Class  \n",
      "0     0.913358      0.007332      0.003147      0.834222      0.998724  SEKER  \n",
      "1     0.953861      0.006979      0.003564      0.909851      0.998430  SEKER  \n",
      "2     0.908774      0.007244      0.003048      0.825871      0.999066  SEKER  \n",
      "3     0.928329      0.007017      0.003215      0.861794      0.994199  SEKER  \n",
      "4     0.970516      0.006697      0.003665      0.941900      0.999166  SEKER  \n",
      "\n",
      "Training set size : 10888\n",
      "\n",
      "Testing set size  : 2723\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "data = pd.read_excel(\"Dry_Bean_Dataset.xlsx\")\n",
    "\n",
    "print(f\"Dataset Name    :  Dry Bean\")\n",
    "print(f\"Dataset Source  :  UCI\")\n",
    "print(f\"No. of Samples  :  {data.shape[0]}\")\n",
    "print(f\"No. of Features :  {data.shape[1]}\")\n",
    "\n",
    "print(\"\\nFirst 5 rows of the raw dataset:\")\n",
    "print(data.head(5))\n",
    "\n",
    "X = data.drop('Class', axis=1)\n",
    "y = data['Class']\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_le = le.fit_transform(y)\n",
    "joblib.dump(le, os.path.join(cwd, 'label_encoder.pkl'))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_le, test_size=0.2, random_state=42, stratify=y_le)\n",
    "\n",
    "print(f\"\\nTraining set size : {X_train.shape[0]}\")\n",
    "print(f\"\\nTesting set size  : {X_test.shape[0]}\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "joblib.dump(scaler, os.path.join(cwd, 'scaler.pkl'))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "726cb339-9e5a-4b62-9760-70cf915aa32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intializing the Models\n",
    "classification_models = {\n",
    "    'logistic_regression': LogisticRegression(max_iter=3000, solver='lbfgs', random_state=42),\n",
    "    'decision_tree': DecisionTreeClassifier(random_state=42),\n",
    "    'knn': KNeighborsClassifier(n_neighbors=5, n_jobs=-1),\n",
    "    'naive_bayes': GaussianNB(),\n",
    "    'random_forest': RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42),\n",
    "    'xgboost': XGBClassifier(eval_metric='mlogloss', n_jobs=-1, random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39d17214-7f6e-44fa-8f2e-901dff37f422",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics = []\n",
    "\n",
    "for name, model in classification_models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    joblib.dump(model, os.path.join(cwd, f'{name}.pkl'))\n",
    "\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    mcc = matthews_corrcoef(y_test, y_pred)\n",
    "\n",
    "    y_proba = model.predict_proba(X_test_scaled)\n",
    "    auc = roc_auc_score(y_test, y_proba, multi_class='ovr', average='weighted')\n",
    "\n",
    "    metrics.append({\n",
    "        'Model': name, 'Accuracy': accuracy, 'AUC': auc, 'Precision': precision,\n",
    "        'Recall': recall, 'F1 Score': f1, 'MCC': mcc\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd0d921f-9eed-413b-8c77-0bdd4c501bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results from all the models:\n",
      "\n",
      "| Model               |   Accuracy |    AUC |   Precision |   Recall |   F1 Score |    MCC |\n",
      "|---------------------|------------|--------|-------------|----------|------------|--------|\n",
      "| logistic_regression |     0.9207 | 0.9934 |      0.9214 |   0.9207 |     0.9208 | 0.9041 |\n",
      "| decision_tree       |     0.8898 | 0.9320 |      0.8896 |   0.8898 |     0.8896 | 0.8669 |\n",
      "| knn                 |     0.9152 | 0.9811 |      0.9158 |   0.9152 |     0.9153 | 0.8974 |\n",
      "| naive_bayes         |     0.8979 | 0.9902 |      0.9005 |   0.8979 |     0.8980 | 0.8772 |\n",
      "| random_forest       |     0.9192 | 0.9910 |      0.9194 |   0.9192 |     0.9191 | 0.9023 |\n",
      "| xgboost             |     0.9280 | 0.9939 |      0.9282 |   0.9280 |     0.9280 | 0.9129 |\n"
     ]
    }
   ],
   "source": [
    "# Print the result metrics\n",
    "df_metrics = pd.DataFrame(metrics)\n",
    "\n",
    "table = tabulate(df_metrics, headers='keys', tablefmt='github', floatfmt=\".4f\", showindex=False)\n",
    "\n",
    "# Print to console\n",
    "print(\"Results from all the models:\\n\")\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647a7409-f53a-45c8-8305-26a798e7954b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
